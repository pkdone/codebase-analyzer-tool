TODO: do these then delete



FIRST TEST NEW RETRY CODE WITH CLAUDE FOR FULL capture



### Implicit Data Flow in Report Generation
*   **Current State:** The `AppReportGenerator` class fetches data from multiple disparate data providers (`AppStatisticsDataProvider`, `CategoriesDataProvider`, `DatabaseReportDataProvider`) and the `SourcesRepository`. It then passes all the collected data as separate arguments to the `HtmlReportWriter` and `JsonReportWriter`. This creates an implicit dependency on a large, unstructured set of data.

*   **Suggestion for Improvement:** Define a clear, unified data model for the report, such as a `ReportData` interface. The `AppReportGenerator` would be responsible for constructing this single, well-defined object. The data providers would contribute to building this object. The `HtmlReportWriter` and `JsonReportWriter` would then accept this single `ReportData` object, making the data contract explicit and simplifying the method signatures.

*   **Affected Files:**
    *   `src/components/reporting/app-report-generator.ts`
    *   `src/components/reporting/html-report-writer.ts`
    *   `src/components/reporting/json-report-writer.ts`
    *   `src/components/reporting/report-gen.types.ts` (to add the new interface)


### Duplication in OpenAI Provider Logic

**Area for Improvement:**
The `OpenAILLM` and `AzureOpenAILLM` classes both extend `BaseOpenAILLM` and contain nearly identical logic within their `buildFullLLMParameters` methods for creating chat completion requests. The only significant difference is the source of the model identifier (`urn` vs. `deployment`). This duplication makes maintenance more difficult.

**Code Reference:**
*   **Files:** `src/llm/providers/openai/openai/openai-llm.ts`, `src/llm/providers/openai/azureOpenai/azure-openai-llm.ts`

**Suggestion:**
Move the common parameter-building logic into the `BaseOpenAILLM` class. Introduce a new protected abstract method, such as `getModelIdentifier(modelKey: string)`, that concrete classes must implement to provide the provider-specific model name or deployment ID.

**Improved Code:**
```typescript
// src/llm/providers/openai/base-openai-llm.ts
export default abstract class BaseOpenAILLM extends AbstractLLM {
  // ...
  protected buildFullLLMParameters(/*...*/) {
    const modelIdentifier = this.getModelIdentifier(modelKey); // New abstract method
    // ... common logic using modelIdentifier
  }
  protected abstract getModelIdentifier(modelKey: string): string;
  // ...
}

// src/llm/providers/openai/openai/openai-llm.ts
export default class OpenAILLM extends BaseOpenAILLM {
  // ...
  protected getModelIdentifier(modelKey: string): string {
    return this.llmModelsMetadata[modelKey].urn;
  }
  // buildFullLLMParameters is now much simpler or removed if all logic is in base.
}

// src/llm/providers/openai/azureOpenai/azure-openai-llm.ts
export default class AzureOpenAILLM extends BaseOpenAILLM {
  // ...
  protected getModelIdentifier(modelKey: string): string {
    const deployment = this.modelToDeploymentMappings.get(modelKey);
    if (!deployment) throw new Error(/*...*/);
    return deployment;
  }
  // buildFullLLMParameters is now much simpler or removed.
}
```
**Affected Files:**
*   `src/llm/providers/openai/base-openai-llm.ts`
*   `src/llm/providers/openai/openai/openai-llm.ts`
*   `src/llm/providers/openai/azureOpenai/azure-openai-llm.ts`



### Unsafe Type Assertion on Repository Data

**Area for Improvement:**
The `CategoriesDataProvider` uses a type assertion `(result as AppSummaryNameDescArray)` to cast the data returned from the repository. This bypasses TypeScript's static type checking and assumes the data structure is correct, which can lead to runtime errors if the data shape changes.

**Code Reference:**
*   **File:** `src/components/reporting/data-providers/categories-data-provider.ts`
    ```typescript
    // ...
    const result = await this.appSummariesRepository.getProjectAppSummaryField(
      projectName,
      category as keyof AppSummaryRecord,
    );
    const data = result ? (result as AppSummaryNameDescArray) : [];
    // ...
    ```

**Suggestion:**
Replace the type assertion with a type guard function that validates the structure of the returned data at runtime. This ensures type safety and makes the code more robust against unexpected data shapes.

**Improved Code:**
```typescript
// src/components/reporting/data-providers/categories-data-provider.ts

function isAppSummaryNameDescArray(data: unknown): data is AppSummaryNameDescArray {
  return Array.isArray(data) && data.every(item => 
    typeof item === 'object' && item !== null && 'name' in item && 'description' in item
  );
}

// ...
const result = await this.appSummariesRepository.getProjectAppSummaryField(/*...*/);
const data = isAppSummaryNameDescArray(result) ? result : [];
// ...
```
**Affected Files:**
*   `src/components/reporting/data-providers/categories-data-provider.ts`



### Inconsistent `catch` Clause Typing

**Area for Improvement:**
The project enables the strict `useUnknownInCatchVariables` TypeScript option, which is a best practice for ensuring type safety in error handling. However, this is not applied consistently. Some `catch` blocks correctly type the error as `unknown`, while others use the less safe `catch (error)`.

**Code Reference:**
*   **File:** `src/components/capture/file-summarizer.ts`
    ```typescript
    // ...
    } catch (error) { // 'error' is implicitly 'any' or 'unknown' based on config, but explicit is better
      const errorMsg = `Failed to generate summary for '${filepath}'`;
      logErrorMsgAndDetail(errorMsg, error);
      return { success: false, error: `${errorMsg}: ${getErrorText(error)}` };
    }
    // ...
    ```

**Suggestion:**
Consistently apply `catch (error: unknown)` across the entire codebase. This forces developers to perform type-checking on the caught error before using it, preventing potential runtime errors and making the error handling logic more explicit and robust.

**Improved Code:**
```typescript
// src/components/capture/file-summarizer.ts

// ...
} catch (error: unknown) { // Explicitly type 'error' as 'unknown'
  const errorMsg = `Failed to generate summary for '${filepath}'`;
  logErrorMsgAndDetail(errorMsg, error);
  return { success: false, error: `${errorMsg}: ${getErrorText(error)}` };
}
// ...
```
**Affected Files:**
*   `src/components/capture/file-summarizer.ts`
*   `src/lifecycle/application-runner.ts`



### Imperative Data Transformation in Reporting

**Area for Improvement:**
The `getStoredProceduresAndTriggers` method in `DatabaseReportDataProvider` uses an imperative approach to process database records. It initializes an empty object and then mutates it within a `for` loop. This style can be harder to follow and more prone to side effects than a functional approach.

**Code Reference:**
*   **File:** `src/components/reporting/data-providers/database-report-data-provider.ts`
    ```typescript
    // ...
    const procsAndTriggers: ProcsAndTriggers = { /* ... initial empty state ... */ };
    // ...
    for (const record of records) {
      // ... logic that mutates procsAndTriggers ...
      this.processDbObjects(
        summary.storedProcedures,
        procsAndTriggers.procs,
        "STORED PROCEDURE",
        record.filepath,
      );
      // ...
    }
    return procsAndTriggers;
    // ...
    ```

**Suggestion:**
Refactor this logic to use functional programming methods like `map`, `filter`, and `reduce`. This would make the data transformation more declarative, predictable, and easier to test, as it would avoid mutating a shared state object within a loop.

**Improved Code Structure:**
```typescript
// src/components/reporting/data-providers/database-report-data-provider.ts

// ...
const allProcs = records.flatMap(record => 
  record.summary?.storedProcedures?.map(proc => ({ ...proc, filepath: record.filepath })) ?? []
);
const allTrigs = records.flatMap(record => 
  record.summary?.triggers?.map(trig => ({ ...trig, filepath: record.filepath })) ?? []
);

const procs = this.aggregateDbObjects(allProcs, "STORED PROCEDURE");
const trigs = this.aggregateDbObjects(allTrigs, "TRIGGER");

return { procs, trigs };
// ... where aggregateDbObjects is a new private method using .reduce()
// ...
```
**Affected Files:**
*   `src/components/reporting/data-providers/database-report-data-provider.ts`



### Parallelize Sequential Asynchronous Operations

**Files:**
*   `src/tasks/code-query.task.ts`
*   `src/components/reporting/data-providers/categories-data-provider.ts`
*   `src/common/utils/markdown-utils.ts`

**Analysis:** Two places in the codebase use a `for...of` loop with an `await` call inside. This pattern processes items sequentially. When the operations are independent, they can be executed in parallel using `Promise.all`, which can significantly improve performance, especially for I/O-bound or network-bound tasks.

**Code to Improve (Example 1):**
```typescript
// src/tasks/code-query.task.ts

private async queryCodebase(): Promise<void> {
  // ...
  const questions = await getTextLines(appConfig.QUESTIONS_PROMPTS_FILEPATH);

  for (const question of questions) {
    const result = await this.codeQuestioner.queryCodebaseWithQuestion(
      question,
      this.projectName,
    );
    console.log(`\n---------------\nQUESTION: ${question}\n\n${result}\n---------------\n`);
  }
}
```

**Suggestion for Improvement (Example 1):**
Use `Promise.all` to execute all codebase queries concurrently.

```typescript
// src/tasks/code-query.task.ts

private async queryCodebase(): Promise<void> {
  // ...
  const questions = await getTextLines(appConfig.QUESTIONS_PROMPTS_FILEPATH);

  const queryPromises = questions.map(async (question) => {
    const result = await this.codeQuestioner.queryCodebaseWithQuestion(
      question,
      this.projectName,
    );
    console.log(`\n---------------\nQUESTION: ${question}\n\n${result}\n---------------\n`);
  });

  await Promise.all(queryPromises);
}
```

**Code to Improve (Example 2):**
```typescript
// src/common/utils/markdown-utils.ts

export async function mergeSourceFilesIntoMarkdownCodeblock(
  filepaths: string[],
  srcDirPath: string,
  ignoreList: readonly string[],
): Promise<string> {
  const contentParts: string[] = [];

  for (const filepath of filepaths) {
    // ... (logic to read file)
    const content = await readFile(filepath);
    contentParts.push(`\n\`\`\` ${relativeFilepath}\n${content.trim()}\n\`\`\`\n`);
  }

  return contentParts.join("").trim();
}
```

**Suggestion for Improvement (Example 2):**
Read all files in parallel to speed up the merging process.

```typescript
// src/common/utils/markdown-utils.ts

export async function mergeSourceFilesIntoMarkdownCodeblock(
  filepaths: string[],
  srcDirPath: string,
  ignoreList: readonly string[],
): Promise<string> {
  const contentPromises = filepaths.map(async (filepath) => {
    const relativeFilepath = filepath.replace(`${srcDirPath}/`, "");
    const type = getFileExtension(filepath).toLowerCase();
    if (ignoreList.includes(type)) return ""; // Skip file

    const content = await readFile(filepath);
    return `\n\`\`\` ${relativeFilepath}\n${content.trim()}\n\`\`\`\n`;
  });

  const contentParts = await Promise.all(contentPromises);
  return contentParts.join("").trim();
}
```


### 3. Use Non-Mutating Array Methods for Immutability

**File:** `src/common/utils/fs-utils.ts`

**Analysis:** The `findFilesRecursively` function uses `Array.prototype.sort()` to order files by size. This method mutates the array in place. ECMAScript 2023 introduced `Array.prototype.toSorted()`, which returns a new sorted array, leaving the original unchanged. Using non-mutating methods promotes functional programming principles and prevents unintended side effects.

**Code to Improve:**
```typescript
// src/common/utils/fs-utils.ts

// ...
return filesWithSizes
  .sort((a, b) => b.size - a.size) // Sort by size, largest first
  .map(({ file }) => file);
// ...
```

**Suggestion for Improvement:**
Replace `.sort()` with `.toSorted()` to create a new sorted array without modifying the original.

```typescript
// src/common/utils/fs-utils.ts

// ...
return filesWithSizes
  .toSorted((a, b) => b.size - a.size) // Use non-mutating sort
  .map(({ file }) => file);
// ...
```



### Simplify Deeply Nested Property Access with Optional Chaining

**File:** `src/llm/providers/vertexai/vertex-ai-gemini/vertex-ai-gemini-llm.ts`

**Analysis:** The `extractEmbeddingsFromPredictions` method contains multiple verbose checks for `null` or `undefined` on deeply nested properties. This pattern is a classic use case for the Optional Chaining (`?.`) operator, which provides a much more concise and readable way to safely access nested properties.

**Code to Improve:**
```typescript
// src/llm/providers/vertexai/vertex-ai-gemini/vertex-ai-gemini-llm.ts

private extractEmbeddingsFromPredictions(/*...*/) {
  if (!predictions) throw new BadResponseContentLLMError("Predictions are null or undefined");
  const embeddings = predictions.map((p) => {
    if (!p.structValue?.fields)
      throw new BadResponseContentLLMError("structValue or fields is null or undefined");
    const embeddingsProto = p.structValue.fields.embeddings;
    if (!embeddingsProto.structValue?.fields)
      throw new BadResponseContentLLMError(/*...*/);
    const valuesProto = embeddingsProto.structValue.fields.values;
    if (!valuesProto.listValue?.values)
      throw new BadResponseContentLLMError(/*...*/);
    return valuesProto.listValue.values.map((v) => {
      if (typeof v.numberValue !== "number")
        throw new BadResponseContentLLMError(/*...*/);
      return v.numberValue;
    });
  });
  return embeddings;
}
```

**Suggestion for Improvement:**
Refactor the nested checks using optional chaining (`?.`) and the nullish coalescing operator (`??`) for a cleaner implementation.

```typescript
// src/llm/providers/vertexai/vertex-ai-gemini/vertex-ai-gemini-llm.ts

private extractEmbeddingsFromPredictions(
  predictions: aiplatform.protos.google.protobuf.IValue[] | null | undefined,
) {
  if (!predictions) {
    throw new BadResponseContentLLMError("Predictions are null or undefined");
  }

  return predictions.map((p) => {
    const values = p.structValue?.fields?.embeddings?.structValue?.fields?.values?.listValue?.values;
    if (!values) {
      throw new BadResponseContentLLMError("Could not extract embedding values from prediction response");
    }
    return values.map((v) => {
      // Use nullish coalescing to throw if numberValue is not a number
      return v.numberValue ?? (() => {
        throw new BadResponseContentLLMError("Embedding value is not a number or is missing", v);
      })();
    });
  });
}
```



### Use Declarative Array Methods for Condition Checking

**File:** `src/llm/providers/bedrock/base-bedrock-llm.ts`

**Analysis:** The `isTokenLimitExceeded` method uses a chain of `||` operators with `String.prototype.includes()` to check for multiple substrings in an error message. This pattern can become unwieldy. A more modern and maintainable approach is to use `Array.prototype.some()` with a list of substrings.

**Code to Improve:**
```typescript
// src/llm/providers/bedrock/base-bedrock-llm.ts

protected isTokenLimitExceeded(error: unknown) {
  if (error instanceof ValidationException) {
    const lowercaseContent = getErrorText(error).toLowerCase();

    if (
      lowercaseContent.includes("too many input tokens") ||
      lowercaseContent.includes("expected maxlength") ||
      lowercaseContent.includes("input is too long") ||
      lowercaseContent.includes("input length") ||
      lowercaseContent.includes("too large for model") ||
      lowercaseContent.includes("please reduce the length of the prompt")
    ) {
      return true;
    }
  }
  return false;
}
```

**Suggestion for Improvement:**
Store the search strings in an array and use `.some()` to check if any of them are present in the error message.

```typescript
// src/llm/providers/bedrock/base-bedrock-llm.ts

protected isTokenLimitExceeded(error: unknown): boolean {
  if (!(error instanceof ValidationException)) {
    return false;
  }

  const errorKeywords = [
    "too many input tokens",
    "expected maxlength",
    "input is too long",
    "input length",
    "too large for model",
    "please reduce the length of the prompt",
  ];

  const lowercaseContent = getErrorText(error).toLowerCase();
  return errorKeywords.some((keyword) => lowercaseContent.includes(keyword));
}
```




### Use Functional Array Methods for Data Transformation

**File:** `src/components/reporting/data-providers/database-report-data-provider.ts`

**Analysis:** The `getDatabaseInteractions` method uses `Array.prototype.map()` but contains conditional logic that throws an error if a condition isn't met. This is an anti-pattern for `map`, whose callback should ideally be a pure transformation function. A better approach is to first filter out invalid records and then map the valid ones.

**Code to Improve:**
```typescript
// src/components/reporting/data-providers/database-report-data-provider.ts

async getDatabaseInteractions(projectName: string): Promise<DatabaseIntegrationInfo[]> {
  const records = await this.sourcesRepository.getProjectDatabaseIntegrations(/*...*/);

  return records.map((record) => {
    const { summary, filepath } = record;
    const databaseIntegration = summary?.databaseIntegration;
    if (summary && databaseIntegration) {
      return { /* ... */ };
    }
    // This should not happen due to the filter above, but satisfies TypeScript
    throw new Error("Record missing required summary or databaseIntegration");
  });
}
```

**Suggestion for Improvement:**
Use `Array.prototype.filter` to remove invalid records before mapping, ensuring the `map` callback is clean and doesn't need to handle error cases.

```typescript
// src/components/reporting/data-providers/database-report-data-provider.ts

async getDatabaseInteractions(projectName: string): Promise<DatabaseIntegrationInfo[]> {
  const records = await this.sourcesRepository.getProjectDatabaseIntegrations(/*...*/);

  return records
    .filter(
      (record): record is { filepath: string; summary: { classpath?: string; databaseIntegration: DatabaseIntegrationInfo } } =>
        !!record.summary?.databaseIntegration,
    )
    .map((record) => ({
      path: record.summary.classpath ?? record.filepath,
      mechanism: record.summary.databaseIntegration.mechanism,
      description: record.summary.databaseIntegration.description,
      codeExample: record.summary.databaseIntegration.codeExample,
    }));
}
```




### Unsafe Type Assertion on Database Query Results

-   **File(s) Affected**:
    -   `src/components/insights/insights-from-db-generator.ts`
    -   `src/components/reporting/data-providers/categories-data-provider.ts`

-   **Code Reference**:
    ```typescript
    // src/components/reporting/data-providers/categories-data-provider.ts
    const result = await this.appSummariesRepository.getProjectAppSummaryField(
      projectName,
      category as keyof AppSummaryRecord,
    );
    const data = result ? (result as AppSummaryNameDescArray) : [];
    ```

-   **Analysis**: The `getProjectAppSummaryField` method returns a value of type `AppSummaryRecord[K]`, which is a specific property from the summary record. However, the calling code casts this result to `AppSummaryNameDescArray`. This assertion is unsafe because not all fields on `AppSummaryRecord` are of this type. It works because the code logic ensures only array-like fields are requested, but the type system doesn't enforce this.

-   **Suggestion**: Refine the repository method or use a type guard to ensure type safety. A type guard is a clean solution.

    ```typescript
    // Create a type guard
    function isAppSummaryNameDescArray(value: unknown): value is AppSummaryNameDescArray {
      return Array.isArray(value) && (value.length === 0 || (typeof value[0] === 'object' && 'name' in value[0] && 'description' in value[0]));
    }
    
    // In src/components/reporting/data-providers/categories-data-provider.ts
    const result = await this.appSummariesRepository.getProjectAppSummaryField(/*...*/);
    
    // Use the type guard instead of assertion
    const data = isAppSummaryNameDescArray(result) ? result : [];
    ```





### Unnecessary and Incorrect Type Assertion in Repository

-   **File(s) Affected**: `src/repositories/source/sources.repository.ts`

-   **Code Reference**:
    ```typescript
    // src/repositories/source/sources.repository.ts
    async insertSource(sourceFileData: SourceRecordNoId): Promise<void> {
      try {
        await this.collection.insertOne(sourceFileData as SourceRecord);
      } catch (error: unknown) {
        // ...
      }
    }
    ```

-   **Analysis**: The `sourceFileData` parameter is of type `SourceRecordNoId` (which lacks an `_id` field), but it's being cast to `SourceRecord` (which includes an `_id` field). This cast is incorrect because the object does not have an `_id` at this point. It's also unnecessary because the MongoDB Node.js driver's `insertOne` method is typed to accept a document without an `_id` (`OptionalId<TSchema>`) and will add it automatically. This cast silences a potential type error and misrepresents the operation.

-   **Suggestion**: Remove the unnecessary type assertion.

    ```typescript
    // src/repositories/source/sources.repository.ts
    async insertSource(sourceFileData: SourceRecordNoId): Promise<void> {
      try {
        // The cast is not needed. The driver handles the type correctly.
        await this.collection.insertOne(sourceFileData);
      } catch (error: unknown) {
        logMongoValidationErrorIfPresent(error);
        throw error;
      }
    }
    ```




### Implicit `any` in Zod Schema Configuration

-   **File(s) Affected**: `src/components/insights/insights.config.ts`

-   **Code Reference**:
    ```typescript
    // src/components/insights/insights.config.ts
    export const summaryCategoriesConfig: Record<
      AppSummaryCategoryEnum,
      {
        label: string;
        description: string;
        schema: z.ZodType; // This is implicitly z.ZodType<any, any, any>
      }
    > = { /* ... */ };
    ```

-   **Analysis**: Using `z.ZodType` without generics defaults to `z.ZodType<any, any, any>`, which weakens type safety. Consumers of this configuration lose information about the shape of the schema they are working with.

-   **Suggestion**: Use a more specific Zod type, such as `z.ZodObject<z.ZodRawShape>`, to indicate that these schemas are expected to be objects. This provides better type inference and safety for functions that use this configuration.

    ```typescript
    // src/components/insights/insights.config.ts
    export const summaryCategoriesConfig: Record<
      AppSummaryCategoryEnum,
      {
        label: string;
        description: string;
        schema: z.ZodObject<z.ZodRawShape>; // Be more specific
      }
    > = { /* ... */ };
    ```





#### Unused Variables and Dead Code
*   **File:** `src/tasks/report-generation.task.ts`
*   **The Bug:** In the `generateReport` method, the `srcDirPath` parameter is received, and a `cleanSrcDirPath` variable is derived from it. However, neither of these variables is used anywhere in the method's logic. The required `projectName` is already injected via the constructor.
*   **How to Fix:** Remove the unused `srcDirPath` parameter from the method signature and delete the `cleanSrcDirPath` variable declaration.

    **Original:**
    ```typescript
    private async generateReport(srcDirPath: string): Promise<void> {
      console.log(`ReportGenerationTask: Generating report for source directory: ${srcDirPath}`);
      const cleanSrcDirPath = srcDirPath.replace(appConfig.TRAILING_SLASH_PATTERN, "");
      console.log(cleanSrcDirPath);
      // ...
    }
    ```
    **Fixed:**
    ```typescript
    private async generateReport(): Promise<void> {
      console.log(`ReportGenerationTask: Generating report for project: ${this.projectName}`);
      await clearDirectory(appConfig.OUTPUT_DIR);
      // ...
    }
    ```
    And update the call in `execute()` to `await this.generateReport();`.




#### Bug 4: Incorrect JSON Report Filename
*   **File:** `src/components/reporting/json-report-writer.ts`
*   **The Bug:** The `writeAllJSONFiles` method prepares a `completeReportData` object to be written to a file. The filename is taken from `jsonFilesConfig.dataFiles.completeReport`, which is `"codebase-report"`. The code does not append a `.json` extension, resulting in a file named `codebase-report` instead of `codebase-report.json`.
*   **How toFix:** Append the `.json` extension when defining the file to be written.

    **In `src/components/reporting/json-report-writer.ts`:**
    ```typescript
    // ...
    const jsonFiles: { /* ... */ }[] = [
      // Complete report file
      { filename: `${jsonFilesConfig.dataFiles.completeReport}.json`, data: completeReportData },
      // ... rest of the array
    ];
    // ...
    ```



#### Documentation and Test File Inconsistencies
*   **Files:**
    *   `README.md`
    *   `tests/config/app.config.test.ts`
    *   `tests/lifecycle/service-runner.test.ts`
*   **The Bugs:**
    1.  **`README.md`**: The commands for running the compiled tools have incorrect paths (e.g., `node ./dist/src/cli/1-capture-codebase.js`). The correct path should be `node ./dist/cli/1-capture-codebase.js`. Also, a date in the future (`17-July-2025`) is used.
    2.  **`tests/config/app.config.test.ts`**: The `describe` block name `appConfig.FILE_SUFFIX_TO_CANONICAL_TYPE_MAPPINGS` contains a typo and should be `appConfig.FILE_EXTENSION_TO_CANONICAL_TYPE_MAPPINGS`.
    3.  **`tests/lifecycle/service-runner.test.ts`**: The file is named `service-runner.test.ts` but it tests `task-executor.ts`, reflecting an outdated naming convention ("Service" vs. "Task").
*   **How to Fix:**
    1.  **`README.md`**: Correct all `node ./dist/src/cli/...` paths to `node ./dist/cli/...`. Correct the date typo.
    2.  **`tests/config/app.config.test.ts`**: Rename the `describe` block to match the constant it is testing.
    3.  **`tests/lifecycle/service-runner.test.ts`**: Rename the file to `task-executor.test.ts` to accurately reflect its purpose.




### Function Name Hiding Complex Logic

-   **File:** `src/llm/core/utils/msgProcessing/error-parser.ts`
-   **Function:** `extractTokensAmountAndLimitFromErrorMsg`
-   **Problem:** The name implies that the function only "extracts" data that is already present in the error message. However, its implementation is more complex; it also **estimates** or **derives** the prompt token count if it's not found, using the prompt's character length as a fallback. The name hides this estimation logic.
-   **Code Reference:**
    ```typescript
    // src/llm/core/utils/msgProcessing/error-parser.ts
    if (promptTokens < 0) {
      // ...
      const estimatedPromptTokensConsumed = Math.floor(
        prompt.length / llmConfig.MODEL_CHARS_PER_TOKEN_ESTIMATE,
      );
      promptTokens = Math.max(estimatedPromptTokensConsumed, assumedMaxTotalTokens + 1);
    }
    ```
-   **Suggested Name:** `calculateTokenUsageFromError`
-   **Reasoning:** Using a verb like "calculate" more accurately communicates that the function may perform computations or estimations to determine the final values, rather than just extracting them.




