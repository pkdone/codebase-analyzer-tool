import { injectable, inject } from "tsyringe";
import { z } from "zod";
import LLMRouter from "../../llm/core/llm-router";
import type { AppSummariesRepository } from "../../repositories/app-summary/app-summaries.repository.interface";
import { TOKENS } from "../../di/tokens";
import type { InsightsGenerator } from "./insights-generator.interface";
import { appConfig } from "../../config/app.config";
import { findFilesRecursively } from "../../common/utils/fs-utils";
import { mergeSourceFilesIntoMarkdownCodeblock } from "../../common/utils/markdown-utils";
import type { EnvVars } from "../../env/env.types";
import { logErrorMsgAndDetail, logWarningMsg } from "../../common/utils/error-utils";
import { createPromptFromConfig } from "../../llm/utils/prompt-templator";
import { LLMOutputFormat } from "../../llm/types/llm.types";
import { summaryCategoriesConfig } from "./insights.config";
import { appSummaryRecordCategoriesSchema } from "./insights.types";

// Type for validating the LLM response for all categories
type AppSummaryRecordCategories = Partial<z.infer<typeof appSummaryRecordCategoriesSchema>>;

// Mark schema trickyfor LLMs to digest - VertexAI seems to struggle with $refs generated by zod
const IS_TRICKY_SCHEMA = true;

/**
 * Class to generate insights from raw code
 */
@injectable()
export default class InsightsFromRawCodeGenerator implements InsightsGenerator {
  // Private fields
  private readonly APP_CATEGORIES_SUMMARIZER_TEMPLATE =
    "Act as a senior developer analyzing the code in a legacy application. Analyze the application's codebase shown below in the section marked 'SOURCES', and based on the code, return a JSON response that contains:\n\n {{specificInstructions}}.\n\nThe JSON response must follow this JSON schema:\n```json\n{{jsonSchema}}\n```\n\n{{forceJSON}}\n\nSOURCES:\n{{codeContent}}";
  private readonly llmProviderDescription: string;

  /**
   * Creates a new InsightsFromRawCodeGenerator.
   */
  constructor(
    @inject(TOKENS.AppSummariesRepository)
    private readonly appSummariesRepository: AppSummariesRepository,
    @inject(TOKENS.LLMRouter) private readonly llmRouter: LLMRouter,
    @inject(TOKENS.ProjectName) private readonly projectName: string,
    @inject(TOKENS.EnvVars) private readonly env: EnvVars,
  ) {
    this.llmProviderDescription = this.llmRouter.getModelsUsedDescription();
  }

  /**
   * Generate insights from raw code and store in the database
   */
  async generateAndStoreInsights(): Promise<void> {
    const srcDirPath = this.env.CODEBASE_DIR_PATH.replace(appConfig.TRAILING_SLASH_PATTERN, "");
    const srcFilepaths = await findFilesRecursively(
      srcDirPath,
      appConfig.FOLDER_IGNORE_LIST,
      appConfig.FILENAME_PREFIX_IGNORE,
    );
    const codeBlocksContent = await mergeSourceFilesIntoMarkdownCodeblock(
      srcFilepaths,
      srcDirPath,
      appConfig.BINARY_FILE_EXTENSION_IGNORE_LIST,
    );
    await this.generateDataForAllCategories(codeBlocksContent);
  }

  /**
   * Generate insights from raw code and store in the database
   */
  private async generateDataForAllCategories(codeBlocksContent: string): Promise<void> {
    try {
      console.log(`Processing all categories in one go`);
      const allCategoriesSummaryData =
        await this.getAllCategoriesSummaryAsValidatedJSON(codeBlocksContent);
      if (!allCategoriesSummaryData) return;
      await this.appSummariesRepository.createOrReplaceAppSummary({
        projectName: this.projectName,
        llmProvider: this.llmProviderDescription,
        ...allCategoriesSummaryData,
      });
      console.log(`Captured summary details of all cateogories into database`);
    } catch (error: unknown) {
      logErrorMsgAndDetail(
        `Unable to generate summary data for all app categories details into database`,
        error,
      );
    }
  }

  /**
   * Generate insights as validated JSON by calling the LLM with a prompt covering all categories
   */
  private async getAllCategoriesSummaryAsValidatedJSON(
    codeBlocksContent: string,
  ): Promise<AppSummaryRecordCategories | null> {
    try {
      const instructions = Object.values(summaryCategoriesConfig)
        .map((category) => `* ${category.description}`)
        .join("\n"); // Concatenate category descriptions. prefixed with "* " followed by newline
      const prompt = this.createInsightsAllCateogriesPrompt(instructions, codeBlocksContent);
      const llmResponse = await this.llmRouter.executeCompletion<AppSummaryRecordCategories>(
        "all-categories",
        prompt,
        {
          outputFormat: LLMOutputFormat.JSON,
          jsonSchema: appSummaryRecordCategoriesSchema,
          hasComplexSchema: IS_TRICKY_SCHEMA,
        },
      );
      return llmResponse;
    } catch (error: unknown) {
      logWarningMsg(
        `${error instanceof Error ? error.message : "Unknown error"} for getting summary data for all categories`,
      );
      return null;
    }
  }

  /**
   * Create a prompt for the LLM to generate insights for all categories
   */
  private createInsightsAllCateogriesPrompt(
    instructions: string,
    codeBlocksContent: string,
  ): string {
    return createPromptFromConfig(
      this.APP_CATEGORIES_SUMMARIZER_TEMPLATE,
      "codebase codeblock",
      instructions,
      appSummaryRecordCategoriesSchema,
      codeBlocksContent,
    );
  }
}
