/**
 * Configuration for insights generation.
 *
 * Use 70% of max tokens to leave generous room for:
 * - Prompt template and instructions (~10-15% of tokens)
 * - LLM response output (~15-20% of tokens)
 *
 * Schema complexity flag for VertexAI compatibility:
 * VertexAI has compatibility issues with complex JSON schemas containing $refs
 * generated by Zod. Individual category schemas are simple and compatible with
 * all providers, so IS_COMPLEX_SCHEMA is false.
 */
export const insightsConfig = {
  CHUNK_TOKEN_LIMIT_RATIO: 0.7,
  /** Individual category schemas are simple - no complex $refs */
  IS_COMPLEX_SCHEMA: false,
} as const;
