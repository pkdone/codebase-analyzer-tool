/**
 * Tuning parameters for insights generation.
 * Use 70% of max tokens to leave generous room for:
 * - Prompt template and instructions (~10-15% of tokens)
 * - LLM response output (~15-20% of tokens)
 */
export const insightsTuningConfig = {
  CHUNK_TOKEN_LIMIT_RATIO: 0.7,
} as const;

/**
 * Schema complexity flags for VertexAI compatibility.
 *
 * VertexAI has compatibility issues with complex JSON schemas containing $refs
 * generated by Zod. These flags indicate whether schemas should be passed to
 * the LLM provider's native JSON mode (when compatible) or handled via text
 * mode with manual parsing (when complex).
 *
 * - Individual category schemas are simple and compatible with all providers
 * - The combined all-categories schema contains complex $refs that are incompatible
 */
export const hasComplexSchema = {
  /** Individual category schemas are simple - no complex $refs */
  INDIVIDUAL_CATEGORY: false,
  /** Combined all-categories schema has complex $refs from zod */
  ALL_CATEGORIES_COMBINED: false,
} as const;
