# ========================================
# LLM Completion Model Chain
# ========================================
# Configure which completion models to use in priority order.
# Format: "modelKey,modelKey,..." (comma-separated model keys)
# The system will try models in order, falling back to the next if one fails.
#
# Available completion model keys:
#   OpenAI:          openai-gpt-5, openai-gpt-4o
#   AzureOpenAI:     azure-gpt-4o, azure-gpt-4-turbo
#   VertexAIGemini:  vertexai-gemini-3-pro, vertexai-gemini-2.5-pro, vertexai-gemini-2.0-flash
#   BedrockClaude:   bedrock-claude-opus-4.5, bedrock-claude-sonnet-4.5
#   BedrockNova:     bedrock-amazon-nova-pro-v1, bedrock-amazon-nova-lite-v1
#   BedrockLlama:    bedrock-meta-llama3-3-70b-instruct, bedrock-meta-llama3-2-90b-instruct
#   BedrockMistral:  bedrock-mistral-large-2407, bedrock-mistral-large-2402
#   BedrockDeepseek: bedrock-deepseek-r1
LLM_COMPLETION_MODEL_CHAIN="vertexai-gemini-3-pro,bedrock-claude-opus-4.5"


# ========================================
# LLM Embedding Model Chain
# ========================================
# Configure which embedding models to use in priority order.
# Format: "modelKey,modelKey,..." (comma-separated model keys)
# The system will try models in order, falling back to the next if one fails.
#
# Available embedding model keys:
#   OpenAI:         openai-text-embedding-3-small
#   AzureOpenAI:    azure-text-embedding-ada-002
#   VertexAIGemini: vertexai-gemini-embedding-001
#   BedrockNova:    bedrock-amazon-titan-embed-text
LLM_EMBEDDING_MODEL_CHAIN="vertexai-gemini-embedding-001"


# ========================================
# General Settings
# ========================================
CODEBASE_DIR_PATH="/home/myname/Projects/sampleapp"
MONGODB_URL="mongodb+srv://myuser:mypassword@mycluster.abc123.mongodb.net/"
SKIP_ALREADY_PROCESSED_FILES=false


# ========================================
# Provider Authentication Settings
# ========================================
# Configure credentials for the providers referenced in your model chains above.
# You only need to configure providers that you're actually using.

# OpenAI API (api key required)
OPENAI_LLM_API_KEY="sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

# Azure OpenAI API (api key + endpoint + deployment names required)
# Each model needs its own deployment name configured in Azure
AZURE_OPENAI_LLM_API_KEY="yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy"
AZURE_OPENAI_ENDPOINT="https://myendpoint.openai.azure.com/"
AZURE_OPENAI_EMBEDDINGS_MODEL_DEPLOYMENT="MyAdaEmbeddingsDeployment"
AZURE_OPENAI_GPT4O_MODEL_DEPLOYMENT="MyGPT4oDeployment"
AZURE_OPENAI_GPT4_TURBO_MODEL_DEPLOYMENT="MyGPT4TurboDeployment"

# GCP VertexAI API (project + locations required; auth via gcloud CLI or service account)
# Note: Use "global" for VERTEXAI_COMPLETIONS_LOCATION for preview models like gemini-3-pro
VERTEXAI_PROJECTID="my-gcp-project"
VERTEXAI_EMBEDDINGS_LOCATION="us-central1"
VERTEXAI_COMPLETIONS_LOCATION="global"

# AWS Bedrock API (auth via AWS CLI credentials or environment variables)
# No additional auth env vars needed - uses standard AWS SDK credential chain


# ========================================
# Model URN Configuration
# ========================================
# Each model in the chain needs its actual URN/identifier configured.
# These can be simple model names, ARNs, or inference profile IDs depending on provider.
# You only need to configure URNs for models you're actually using in your chains.

# OpenAI Model URNs
OPENAI_EMBEDDING_3_SMALL_MODEL_URN="text-embedding-3-small"
OPENAI_GPT5_MODEL_URN="gpt-5"
OPENAI_GPT4O_MODEL_URN="gpt-4o"

# Azure OpenAI Model URNs
AZURE_OPENAI_ADA_EMBEDDINGS_MODEL_URN="text-embedding-ada-002"
AZURE_OPENAI_GPT4O_MODEL_URN="gpt-4o"
AZURE_OPENAI_GPT4_TURBO_MODEL_URN="gpt-4-turbo"

# VertexAI Gemini Model URNs
VERTEXAI_GEMINI_EMBEDDING_001_MODEL_URN="gemini-embedding-001"
VERTEXAI_GEMINI_3_PRO_MODEL_URN="gemini-3-pro-preview"
VERTEXAI_GEMINI_25_PRO_MODEL_URN="gemini-2.5-pro"
VERTEXAI_GEMINI_20_FLASH_MODEL_URN="gemini-2.0-flash-001"

# Bedrock Model URNs (can be model IDs, ARNs, or cross-region inference profile IDs)BEDROCK_TITAN_EMBEDDINGS_MODEL_URN="amazon.titan-embed-text-v1"
BEDROCK_CLAUDE_OPUS_45_MODEL_URN="global.anthropic.claude-opus-4-5-20251101-v1:0"
BEDROCK_CLAUDE_SONNET_45_MODEL_URN="arn:aws:bedrock:us-west-2:111111111111:inference-profile/us.anthropic.claude-sonnet-4-5-20250929-v1:0"
BEDROCK_NOVA_PRO_MODEL_URN="arn:aws:bedrock:us-west-2:111111111111:inference-profile/us.amazon.nova-pro-v1:0"
BEDROCK_NOVA_LITE_MODEL_URN="arn:aws:bedrock:us-west-2:111111111111:inference-profile/us.amazon.nova-lite-v1:0"
BEDROCK_LLAMA_33_70B_MODEL_URN="us.meta.llama3-3-70b-instruct-v1:0"
BEDROCK_LLAMA_32_90B_MODEL_URN="us.meta.llama3-2-90b-instruct-v1:0"
BEDROCK_MISTRAL_LARGE_2407_MODEL_URN="mistral.mistral-large-2407-v1:0"
BEDROCK_MISTRAL_LARGE_2402_MODEL_URN="mistral.mistral-large-2402-v1:0"
BEDROCK_DEEPSEEK_R1_MODEL_URN="arn:aws:bedrock:us-west-2:111111111111:inference-profile/us.deepseek.r1-v1:0"

